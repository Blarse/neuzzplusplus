{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure logger\n",
    "logger = logging.getLogger(\"neuzzpp\")\n",
    "logger.setLevel(logging.INFO)\n",
    "console_logger = logging.StreamHandler(sys.stdout)\n",
    "log_formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "console_logger.setFormatter(log_formatter)\n",
    "logger.addHandler(console_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948271e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Analysis parameters\n",
    "n_tests = 100\n",
    "trial = 0  # Index for the trial run (0-29)\n",
    "rng_seeds = [\n",
    "    7739,\n",
    "    6545,\n",
    "    4388,\n",
    "    4330,\n",
    "    8585,\n",
    "    859,\n",
    "    6973,\n",
    "    2014,\n",
    "    941,\n",
    "    5264,\n",
    "    9756,\n",
    "    7357,\n",
    "    7611,\n",
    "    7174,\n",
    "    7860,\n",
    "    5132,\n",
    "    1281,\n",
    "    8397,\n",
    "    4503,\n",
    "    5003,\n",
    "    3707,\n",
    "    1825,\n",
    "    9267,\n",
    "    7815,\n",
    "    6438,\n",
    "    4024,\n",
    "    8227,\n",
    "    5454,\n",
    "    4434,\n",
    "    4504,\n",
    "]  # Same seeds as the 30 runs\n",
    "random_seed = rng_seeds[trial]\n",
    "\n",
    "# ML training parameters\n",
    "validation_split = 0.1\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "early_stopping = 10\n",
    "add_unseen_neighbors = False\n",
    "percentile_len = 80\n",
    "hidden_neurons = 4096\n",
    "lr = 1e-4\n",
    "\n",
    "# Define paths - adapt to your values\n",
    "root_folder = pathlib.Path(\"/shared\")\n",
    "target_name = \"harfbuzz-1.3.2\"\n",
    "target = root_folder / \"binaries\" / (target_name + \".aflpp\")\n",
    "fuzzer = \"NEUZZPP\"\n",
    "tests_path = (\n",
    "    root_folder\n",
    "    / \"results\"\n",
    "    / \"baselines\"\n",
    "    / target_name\n",
    "    / fuzzer\n",
    "    / f\"trial-{trial}\"\n",
    "    / \"default\"\n",
    "    / \"queue\"\n",
    ")\n",
    "tests_list = [test for test in tests_path.glob(\"id*\")]\n",
    "model_path = tests_path.parent / \"models\"\n",
    "grads_path = tests_path.parent / \"grads\"\n",
    "\n",
    "# Create missing folders\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "grads_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8faef3",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuzzpp.data_loaders import CoverageSeedHandler, seed_data_generator\n",
    "\n",
    "data_loader = CoverageSeedHandler(\n",
    "    seeds_path=tests_path,\n",
    "    target=[str(target)],\n",
    "    percentile_len=percentile_len,\n",
    "    validation_split=validation_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f26a5",
   "metadata": {},
   "source": [
    "Try to load trained model for this fuzzing campaign, otherwise train it on the full corpus (but keep 10% of the data for validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from neuzzpp.models import MLP\n",
    "from neuzzpp.utils import LRTensorBoard, print_confusion_matrix\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    seed_handler,\n",
    "    random_seed,\n",
    "    batch_size,\n",
    "    val_split,\n",
    "    seeds,\n",
    "    epochs,\n",
    "    early_stopping,\n",
    "    lr,\n",
    "    n_hidden_neurons,\n",
    "    fast: bool = False,\n",
    "):\n",
    "    # Create data generators\n",
    "    seed_handler.load_seeds_from_folder()\n",
    "    seed_handler.split_dataset(random_seed=random_seed)\n",
    "    training_generator = seed_handler.get_generator(\n",
    "        batch_size=batch_size, subset=\"training\"\n",
    "    )\n",
    "    if val_split > 0.0:\n",
    "        validation_generator = seed_handler.get_generator(\n",
    "            batch_size=batch_size, subset=\"validation\"\n",
    "        )\n",
    "        monitor_metric = \"val_prc\"\n",
    "    else:\n",
    "        validation_generator = None\n",
    "        monitor_metric = \"prc\"\n",
    "\n",
    "    # Compute class frequencies and weights\n",
    "    class_weights, initial_bias = seed_handler.get_class_weights()\n",
    "\n",
    "    # Create training callbacks\n",
    "    seeds_path = pathlib.Path(seeds)\n",
    "    model_path = seeds_path.parent / \"models\"\n",
    "    callbacks = []\n",
    "    if not fast:\n",
    "        model_save = ModelCheckpoint(\n",
    "            str(model_path / \"model.h5\"),\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            monitor=monitor_metric,\n",
    "            mode=\"max\",\n",
    "        )\n",
    "        callbacks.append(model_save)\n",
    "    if early_stopping is not None:\n",
    "        es = EarlyStopping(monitor=monitor_metric, patience=early_stopping, mode=\"max\")\n",
    "        callbacks.append(es)\n",
    "\n",
    "    # Create model\n",
    "    if not fast:\n",
    "        tb_callback = LRTensorBoard(\n",
    "            log_dir=str(model_path / \"tensorboard\"), write_graph=False\n",
    "        )\n",
    "        callbacks.append(tb_callback)\n",
    "    model = MLP(\n",
    "        input_dim=seed_handler.max_file_size,\n",
    "        output_dim=seed_handler.max_bitmap_size,\n",
    "        lr=lr,\n",
    "        ff_dim=n_hidden_neurons,\n",
    "        output_bias=initial_bias,\n",
    "        fast=fast,\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    model.model.fit(\n",
    "        training_generator,\n",
    "        steps_per_epoch=np.ceil(seed_handler.training_size / batch_size),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=None\n",
    "        if validation_generator is None\n",
    "        else np.ceil(seed_handler.val_size / batch_size),\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        # class_weight=class_weights,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    # Compute confusion matrix on validation data\n",
    "    if val_split > 0.0 and not fast:\n",
    "        class_threshold = 0.5  # Classification threshold, for now hard-coded\n",
    "        val_gen = seed_data_generator(\n",
    "            *seed_handler.val_set, batch_size, seed_handler.max_file_size\n",
    "        )\n",
    "        preds_val = model.model.predict(\n",
    "            val_gen, steps=np.ceil(seed_handler.val_size / batch_size)\n",
    "        )\n",
    "        cm = confusion_matrix(\n",
    "            seed_handler.val_set[1].flatten(),\n",
    "            preds_val.flatten() > class_threshold,\n",
    "            normalize=\"all\",\n",
    "        )\n",
    "        print(f\"Confusion matrix @{class_threshold}\\n\")\n",
    "        print_confusion_matrix(cm, labels=[\"0\", \"1\"])\n",
    "\n",
    "    return model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd1371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from neuzzpp.models import create_logits_model\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_path / \"model.h5\")\n",
    "    data_loader.load_seeds_from_folder()\n",
    "except IOError:\n",
    "    logger.warning(\n",
    "        f\"No trained model found at {model_path / 'model.h5'}. Training new model.\"\n",
    "    )\n",
    "    model = train_model(\n",
    "        data_loader,\n",
    "        random_seed=random_seed,\n",
    "        batch_size=batch_size,\n",
    "        val_split=validation_split,\n",
    "        seeds=tests_path,\n",
    "        epochs=n_epochs,\n",
    "        early_stopping=early_stopping,\n",
    "        lr=lr,\n",
    "        n_hidden_neurons=hidden_neurons,\n",
    "    )\n",
    "grad_model = create_logits_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce7aab",
   "metadata": {},
   "source": [
    "# Gradient precomputation\n",
    "Randomly select `n_tests` test cases from the corpus for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d94518",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_tests is not None:\n",
    "    rng = np.random.default_rng(seed=random_seed)\n",
    "    tests_indices = rng.choice(\n",
    "        data_loader.reduced_bitmap.shape[0], n_tests, replace=False\n",
    "    )\n",
    "    tests_list = [data_loader.seed_list[i] for i in tests_indices]\n",
    "    bitmap = data_loader.reduced_bitmap[tests_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3777de",
   "metadata": {},
   "source": [
    "For the selected test cases, compute and serialize the gradient value for targeting each edge for mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from neuzzpp.data_loaders import get_seed_len, load_normalized_seeds\n",
    "from neuzzpp.mutations import compute_gradient\n",
    "\n",
    "\n",
    "def generate_all_grads(seed_list, bitmap, model, mutation_strategy: str = \"sign\"):\n",
    "    input_dim = model.input.shape.as_list()[-1]\n",
    "    grads_folder = seed_list[0].parent.parent / \"grads\"\n",
    "\n",
    "    # Compute and store gradient info to file\n",
    "    for seed_name in tqdm(seed_list):\n",
    "        # Read seed\n",
    "        seed = load_normalized_seeds([seed_name], max_len=input_dim)\n",
    "        len_seed = get_seed_len(seed_name)\n",
    "        n_keep_vals = min(len_seed, input_dim)\n",
    "\n",
    "        grad_name = grads_folder / seed_name.name\n",
    "        if not grad_name.exists():\n",
    "            with open(grad_name, \"a\") as f:\n",
    "                for edge in range(bitmap.shape[-1]):\n",
    "                    # Compute gradient direction for seed\n",
    "                    sorting_index, gradient = compute_gradient(\n",
    "                        model, edge, seed, n_keep_vals, mutation_strategy\n",
    "                    )\n",
    "\n",
    "                    # Write gradient info to file\n",
    "                    sorting_index = [str(el) for el in sorting_index]\n",
    "                    gradient = [str(int(el)) for el in gradient]\n",
    "                    f.write(\",\".join(sorting_index) + \"|\" + \",\".join(gradient) + \"\\n\")\n",
    "        else:\n",
    "            logger.warning(f\"Found existing gradient file for {grad_name}. Skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store gradients\n",
    "generate_all_grads(tests_list, bitmap, grad_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe6e9a",
   "metadata": {},
   "source": [
    "# Mutation of targeted addresses\n",
    "Use the previously computed gradients to compute all mutations targetting each test case and possible edge. The mutations are generated using the same strategy as Neuzz, PreFuzz and Neuzz++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_path = grads_path.parent / \"mutations\"\n",
    "mut_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuzzpp.mutations import compute_mutations_success_all\n",
    "\n",
    "compute_mutations_success_all(model, tests_list, mut_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1445e",
   "metadata": {},
   "source": [
    "# Analysis of targeted addresses\n",
    "First, load the selected test cases and get coverage predictions for them from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ee451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuzzpp.data_loaders import load_normalized_seeds\n",
    "from neuzzpp.models import predict_coverage\n",
    "\n",
    "tests = load_normalized_seeds(tests_list, max_len=model.input.shape.as_list()[-1])\n",
    "tests_preds = predict_coverage(model, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d7fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot = sns.heatmap(\n",
    "    tests_preds,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cmap=plt.cm.get_cmap(\"flare_r\", 2),\n",
    "    #     yticklabels=[seed_file.stem for seed_file in tests_list],\n",
    ")\n",
    "\n",
    "# Customize labels\n",
    "plot.set_title(\"Coverage of code edge by test case\")\n",
    "plot.set_xlabel(\"Edge ID\")\n",
    "plot.set_ylabel(\"Test ID\")\n",
    "plt.yticks(np.arange(0, n_tests, 5), np.arange(0, n_tests, 5), rotation=0)\n",
    "\n",
    "# Segment colorbar in legend\n",
    "colorbar = plot.collections[0].colorbar\n",
    "colorbar.set_ticks([0.25, 0.75])\n",
    "colorbar.set_ticklabels([\"Not covered\", \"Covered\"])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a691cd",
   "metadata": {},
   "source": [
    "Load coverage information for each seed and target edge (precomputed in previous section):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coverage counts for mutations\n",
    "summaries = {cov_file.stem: np.load(cov_file) for cov_file in mut_path.glob(\"**/*.npy\")}\n",
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize coverage of mutations to \"reached\" (True) or \"not reached\" (False)\n",
    "summaries_binary = {\n",
    "    test_case: coverage != 0 for test_case, coverage in summaries.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_coverage = np.stack(\n",
    "    [np.diag(summaries_binary[test.name]) for test in tests_list],\n",
    "    axis=0,\n",
    ")\n",
    "mutations_coverage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f84590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include coverage from original test cases (without mutations) as separate value\n",
    "mutations_coverage = np.where(tests_preds == True, 0.5, mutations_coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d919f",
   "metadata": {},
   "source": [
    "Plot heatmap of mutations success per seed and targeted edge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plot = sns.heatmap(\n",
    "    mutations_coverage,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cmap=plt.cm.get_cmap(\"flare_r\", 3),\n",
    ")\n",
    "\n",
    "# Customize labels\n",
    "plot.set_title(\"Coverage of code edge by test case\")\n",
    "plot.set_xlabel(\"Targeted edge ID\")\n",
    "plot.set_ylabel(\"Test ID\")\n",
    "plt.yticks(np.arange(0, n_tests, 5), np.arange(0, n_tests, 5), rotation=0)\n",
    "\n",
    "# Segment colorbar in legend\n",
    "colorbar = plot.collections[0].colorbar\n",
    "colorbar.set_ticks([0.18, 0.5, 0.82])\n",
    "colorbar.set_ticklabels([\"Not covered\", \"Original coverage\", \"Mutations coverage\"])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store computed coverage for future plotting\n",
    "with open(tests_path.parent / \"coverage_plot.npy\", \"wb\") as save_file:\n",
    "    np.save(save_file, mutations_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ecd6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
